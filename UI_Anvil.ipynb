{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e496d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demonstrated-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "def generate_vgg16(num_classes, in_shape = (224,224,3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same',name='block1_conv1', input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv1'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv2'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv1'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv2'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "    # Classification block\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(512, activation='relu', name='fc1',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.l2(0.01),\n",
    "    activity_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(512, activation='relu', name='fc2',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.l2(0.01),\n",
    "    activity_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "    return model\n",
    "\n",
    "race_modelm=generate_vgg16(7)\n",
    "optm = keras.optimizers.RMSprop(lr = 0.00008, decay = 1e-6)\n",
    "race_modelm.compile(loss=keras.losses.categorical_crossentropy, optimizer=optm,metrics=['accuracy'])\n",
    "race_modelm.load_weights('58_Mask_55_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "color-quarter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from keras) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from keras) (5.4.1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9b5e69352f73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip3 install tensorflow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip3 install opencv-python keras'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install opencv-python keras\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "#import numpy as np\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "def generate_vgg16(num_classes, in_shape = (224,224,3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same',name='block1_conv1', input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv1'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv2'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv1'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv2'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "    # Classification block\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(512, activation='relu', name='fc1',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.l2(0.03),\n",
    "    activity_regularizer=regularizers.l2(0.03)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(512, activation='relu', name='fc2',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.l2(0.05),\n",
    "    activity_regularizer=regularizers.l2(0.05)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "    return model\n",
    "\n",
    "race_model=generate_vgg16(7)\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr = 0.00008, decay = 1e-6)\n",
    "race_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt,metrics=['accuracy'])\n",
    "race_model.load_weights('53.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liberal-cemetery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import anvil.server\n",
    "anvil.server.connect(\"GGNOLAT2ELYHYFYJ5CR64PZ3-THY2SMDMP2NSMXNO\")\n",
    "import tensorflow as tf\n",
    "import anvil.media\n",
    "import numpy\n",
    "@anvil.server.callable\n",
    "def predict_modelrace(file):\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        #image1 = tf.keras.preprocessing.image.load_img(filename)\n",
    "        #testing_im=[]\n",
    "\n",
    "        labels =['Black', 'East Asian', 'Indian', 'Latino_Hispanic','Middle Eastern', 'Southeast Asian', 'White']\n",
    "\n",
    "        #testing_im.append(sample_face_race)\n",
    "        face=cv2.imread(filename) \n",
    "        plt.imshow(face)\n",
    "        \n",
    "        #face =image1\n",
    "        #gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        #face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "\n",
    "        #faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        #faces1=[]\n",
    "        #for (x, y, w, h) in faces:\n",
    "        #cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            #faces1.append(face[y:y + h, x:x + w])\n",
    "        faces = RetinaFace.extract_faces(filename, align = True)\n",
    "        for face in faces:\n",
    "            plt.imshow(face[...,::-1])\n",
    "            plt.show()\n",
    "        try:\n",
    "            face=faces[0]\n",
    "            print('cropped race no mask')\n",
    "        except:\n",
    "            face=face\n",
    "        #open_img(face)\n",
    "        img = face\n",
    "    \n",
    "        width =224\n",
    "        height =224\n",
    "        dim = (width, height)\n",
    "\n",
    "\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)  \n",
    "        face=resized\n",
    "\n",
    "        #open_img(face1)\n",
    "        f1=list()\n",
    "        f1.append(face)\n",
    "        f1=np.asarray(f1)\n",
    "        pre_im_race = race_model.predict(f1)\n",
    "        p=pre_im_race[0]\n",
    "        i=np.argmax(p)\n",
    "        print(labels[i])\n",
    "        \n",
    "        return (labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "patent-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@anvil.server.callable\n",
    "def predict_modelracem(file):\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "      \n",
    "\n",
    "        #image1 = tf.keras.preprocessing.image.load_img(filename)\n",
    "        #testing_im=[]\n",
    "\n",
    "        labels =['Black', 'East Asian', 'Indian', 'Latino_Hispanic','Middle Eastern', 'Southeast Asian', 'White']\n",
    "\n",
    "        #testing_im.append(sample_face_race)\n",
    "        face=cv2.imread(filename) \n",
    "        plt.imshow(face)\n",
    "        #face =image1\n",
    "        #gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        #face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "\n",
    "        #faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        #faces1=[]\n",
    "        #for (x, y, w, h) in faces:\n",
    "        #cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            #faces1.append(face[y:y + h, x:x + w])\n",
    "        faces = RetinaFace.extract_faces(filename, align = True)\n",
    "        for face in faces:\n",
    "            plt.imshow(face[...,::-1])\n",
    "            plt.show()\n",
    "        try:\n",
    "            face=faces[0]\n",
    "            \n",
    "            print('cropped')\n",
    "        except:\n",
    "            face=face\n",
    "        #open_img(face)\n",
    "        img = face\n",
    "    \n",
    "        width =224\n",
    "        height =224\n",
    "        dim = (width, height)\n",
    "\n",
    "\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)  \n",
    "        face=resized\n",
    "\n",
    "        #open_img(face1)\n",
    "        f1=list()\n",
    "        f1.append(face)\n",
    "        f1=np.asarray(f1)\n",
    "        pre_im_race = race_modelm.predict(f1)\n",
    "        p=pre_im_race[0]\n",
    "        i=np.argmax(p)\n",
    "        print(labels[i])\n",
    "        \n",
    "        return (labels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "secondary-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('gender_model_64.h5')\n",
    "\n",
    "@anvil.server.callable\n",
    "def predict_gendermodel(file):\n",
    "    with anvil.media.TempFile(file) as path:\n",
    "        testing_im=[]\n",
    "        model = load_model('gender_model_64.h5')\n",
    "\n",
    "        sample_face = cv2.imread(r\"C:\\Users\\sudhamshu\\Desktop\\Images14KWithMask\\1-WithMask.jpg\")\n",
    "        sample_face = cv2.resize(sample_face, (64,64) )\n",
    "\n",
    "        testing_im.append(sample_face)\n",
    "        face = cv2.imread(path)\n",
    "        face = cv2.resize(face, (64,64) )\n",
    "        testing_im.append(face)\n",
    "\n",
    "        testing_imggg=np.squeeze(testing_im)\n",
    "        tpp = testing_imggg.astype('float32')\n",
    "        tpp /= 255\n",
    "\n",
    "        pre_im = model.predict(tpp)\n",
    "\n",
    "        if pre_im[1][0]>=pre_im[1][1]:\n",
    "            return (\"Male\", pre_im[1][0])\n",
    "        else:\n",
    "            return (\"Female\", pre_im[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-nerve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-supplement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-request",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-selling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
